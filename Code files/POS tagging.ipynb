{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5817769556656125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown                                                               \n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "\n",
    "# the Default Tagger\n",
    "raw = 'I do not like green eggs and ham, I do not like them Sam I am!'                      # Tagger that tags everything as NN\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "default_tagger.tag(tokens)\n",
    "default_tagger.evaluate(brown_tagged_sents)\n",
    "\n",
    "#The Regexp tagger\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),                                                                     # gerunds\n",
    "    (r'.*ed$', 'VBD'),                                                                      # simple past\n",
    "    (r'.*es$', 'VBZ'),                                                                      # 3rd singular present\n",
    "    (r'.*ould$', 'MD'),                                                                     # modals\n",
    "    (r'.*\\'s$', 'NN$'),                                                                     # possessive nouns\n",
    "    (r'.*s$', 'NNS'),                                                                       # plural nouns\n",
    "    (r'^-?[0-9]+(\\.[0-9]+)?$', 'CD'),                                                       # cardinal numbers\n",
    "    (r'.*', 'NN')                                                                           # nouns (default)\n",
    "]\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)                                                 # regular expression tagger\n",
    "regexp_tagger.tag(brown_sents[3])\n",
    "regexp_tagger.evaluate(brown_tagged_sents)\n",
    "\n",
    "#The Lookup Tagger\n",
    "fd = nltk.FreqDist(brown.words(categories='news'))                                          # frequency distribution\n",
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))                       # Conditional frequency distribution\n",
    "most_freq_words = fd.most_common(100)\n",
    "likely_tags = dict((word, cfd[word].max()) for (word, _) in most_freq_words)\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags,\n",
    "                                    backoff=nltk.DefaultTagger('NN'))                       # unigram tagger\n",
    "baseline_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('green', 'NN'),\n",
       " ('eggs', 'NN'),\n",
       " ('and', 'NN'),\n",
       " ('ham', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('them', 'NN'),\n",
       " ('Sam', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('am', 'NN'),\n",
       " ('!', 'NN')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'I do not like green eggs and ham, I do not like them Sam I am!'\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "default_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13089484257215028"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tagger.evaluate(brown_tagged_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regex tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),                # gerunds\n",
    "    (r'.*ed$', 'VBD'),                 # simple past\n",
    "    (r'.*es$', 'VBZ'),                 # 3rd singular present\n",
    "    (r'.*ould$', 'MD'),                # modals\n",
    "    (r'.*\\'s$', 'NN$'),                # possessive nouns\n",
    "    (r'.*s$', 'NNS'),                  # plural nouns\n",
    "    (r'^-?[0-9]+(\\.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "    (r'.*', 'NN')                      # nouns (default)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20186168625812995"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "regexp_tagger.tag(brown_sents[3])\n",
    "regexp_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look up Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5817769556656125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(brown.words(categories='news'))                                          # frequency distribution\n",
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))                       # Conditional frequency distribution\n",
    "most_freq_words = fd.most_common(100)\n",
    "likely_tags = dict((word, cfd[word].max()) for (word, _) in most_freq_words)\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags,\n",
    "                                    backoff=nltk.DefaultTagger('NN'))                       # unigram tagger\n",
    "baseline_tagger.evaluate(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e2823b6ce2f64e483fa1686b0df7f35653b3167a56745627d38778c836e640f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
